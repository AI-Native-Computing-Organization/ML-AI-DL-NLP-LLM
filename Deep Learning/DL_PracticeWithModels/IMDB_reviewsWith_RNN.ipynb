{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z82c-Fcay0a3"
      },
      "source": [
        "## Stage 1: Install dependencies and setting up GPU environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoH0-SMEOy-j",
        "outputId": "9479db21-cffc-4e82-9ed6-d3a1a2d0b45d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install numpy"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL3SBH6PzDwV"
      },
      "source": [
        "## Stage 2: Importing project dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynShOu8nNtFt"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets import imdb #imdb dataset https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7-sPdOzf5l",
        "outputId": "39db771a-af2e-4f9d-c237-c4f4fe24a927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.17.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEjlM2EazOf0"
      },
      "source": [
        "## Stage 3: Dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB0tNtXJzTfA"
      },
      "source": [
        "### Setting up dataset parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw6_KU24SrYK"
      },
      "source": [
        "number_of_words = 20000\n",
        "max_len = 100 #max review length will be 100.If the review is less than that, rest of that will be padding."
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePywR8A4zaxT"
      },
      "source": [
        "### Loading the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kCTV_hjOKmE"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=number_of_words) #we are taking all the reviews that have 20k most frequent words"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZKDNoTKzi5w"
      },
      "source": [
        "### Padding all sequences to be the same length\n",
        "\n",
        "Time to pad all the sequences to be the same length.\n",
        "\n",
        "And so as we said, we're going to make sure that our reviews after being padded, will have 100 elements and the rest of the elements, if the review doesn't have 100 elements, will just be pad tokens just to finish the sequence up to 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHcMNzv7Pd1s"
      },
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len) #for X_train"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcxd--ESP3Rh"
      },
      "source": [
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len) #fir X_test"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xDMP44Zz0dU"
      },
      "source": [
        "### Setting up Embedding Layer parameters\n",
        "\n",
        "The embedding layer is actually a layer used to create a word vector representation of the words, you know, the words and the reviews so that instead of using pre-trained word vectors as if you had the reviews in vectors of words with the padding included, well, we're going to use what we call this\n",
        "embedding layer to train the word vectors in a large matrix.\n",
        "\n",
        "And this large matrix will be a matrix where each row corresponds to a word. You know, all the 20,000 words in our reviews and the columns are actually encoding the word with what we call a representation of the word in the dataset vocabulary.\n",
        "\n",
        "So by using this embedding layer, we're going to learn those word representations jointly with the weights in the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGHQ2upgQIGj",
        "outputId": "4ef4fb0e-d061-4f41-b11b-df59c944b97a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_size = number_of_words\n",
        "vocab_size"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMyk2JcPQcjF"
      },
      "source": [
        "embed_size = 128"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG6LBKGnz7jT"
      },
      "source": [
        "## Step 4: Building a Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUVnz-9K0DcW"
      },
      "source": [
        "### Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2GHzwk6OMrV"
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnXJZYR-0HXE"
      },
      "source": [
        "### Adding the Embeding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWqC0DXbO9FU"
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(vocab_size, embed_size, input_shape=(X_train.shape[1],)))\n",
        "\n",
        "#vocab_size =  the input dimension. You know, before we create this embedding matrix. And the input dimension is simply the number of words. Because remember, in this matrix, each row corresponds to each of the 20,000 words among all our reviews.\n",
        "#embed_size = Then the second argument is output dim, and you might guess what it is. It is, of course, the number of columns that are going to embed each word into this large representation of words in our embedding matrix. And so we're going to choose\n",
        "#128 columns to represent the words, you know, to encode the words. And so, well, you will get an embedding matrix composed of 128 columns.\n",
        "\n",
        "#then the input shape from training data. And the shape itself is actually the second element of this tensor meaning of index one.\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM-lpTZX1mEG"
      },
      "source": [
        "### Adding the LSTM Layer\n",
        "\n",
        "- units: 128\n",
        "- activation: tanh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7IXqhjQpAl"
      },
      "source": [
        "model.add(tf.keras.layers.LSTM(units=128, activation='tanh')) #LSTM Layer mostly uses tanh activation function."
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T9M5Ult10XM"
      },
      "source": [
        "### Adding the Dense output layer\n",
        "\n",
        "- units: 1\n",
        "- activation: sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe1nHzq7Q91-"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) #as we are expencing 0 or 1 as output (negative or positiobe), we take just 1 neuron in output"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWcqM4Yr2ALS"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z9ACOXcRUUN"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) #rmsprop is mostly  used in RNN, As we have 0 or 1 in output; we use binary_crossentropy, then the accuracy as metrics as binary classification"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiolKKO6RjVF",
        "outputId": "cb746743-d040-40b1-eff9-dcf19c504435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,691,713\u001b[0m (10.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,691,713</span> (10.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,691,713\u001b[0m (10.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,691,713</span> (10.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bPUvbfe2GJI"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FqUTA1CRpQ8",
        "outputId": "3aa84d84-1433-4727-bcbc-68356fc1e9ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=3, batch_size=128) #we are going to feed different batches which has 128 data each time and epochs=3 means, the whole data will be trained 3 times"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.5971 - loss: 0.6494\n",
            "Epoch 2/3\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8227 - loss: 0.4039\n",
            "Epoch 3/3\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8624 - loss: 0.3285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e74efafb5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GJ4irh1bCX7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wMo2wYpbCgb"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8kD_6q-RySO",
        "outputId": "f8396a81-9269-46a6-fb73-161df98afb38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss, test_acurracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0XnUtS-cEeI",
        "outputId": "1f3a5842-f2b5-4c56-d365-36f83e5e8ef9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Test accuracy: {}\".format(test_acurracy))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8493599891662598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN9QK49W3C29"
      },
      "source": [],
      "execution_count": 65,
      "outputs": []
    }
  ]
}